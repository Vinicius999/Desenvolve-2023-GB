 

# Aprofundando no Airflow: Executores Local e Celery

### Resumo do Curso

- Aprenda como utilizar o Python para criar aplicações Spark
- Descubra como fazer ciência de dados com as ferramentas do Spark
- Conheça o DataFrame do Spark
- Manipule conjuntos de dados volumosos
- Conheça e crie arquivos utilizados em projetos Big Data

### Aula 01 - Começando o trabalho 

- Conhecemos o projeto Apache Spark.
- Falamos sobre a interface para Apache Spark em Python.
- Conhecemos os recursos do Spark.
- Aprendemos a configurar o Spark no sistema operacional Windows.
- Vimos como utilizar o Spark em nosso notebook do Colab.

### Aula 02 - Carregamento de dados

- Como iniciar uma SparkSession.
- Conhecemos os métodos e atributos básicos da classe SparkSession.
- Como criar Spark DataFrames.
- Como carregar conteúdo de arquivos CSV particionados em uma DataFrame do Spark.

### Aula 03 - Manipulando os dados

- Como alterar os nomes das colunas de um DataFrame.
- Como identificar os tipos de variáveis em um DataFrames.
- Os tipos de dados suportados pelo Spark.
- Algumas funções básicas do Spark e como aplicá-las.
- Como fazer algumas conversões de tipo.

### Aula 04 - Seleções e consultas

- Selecionar colunas específicas de um DataFrame.
- Criar colunas em um DataFrame.
- Ordenar os dados de um DataFrame.
- Fazer filtros com as colunas de um DataFrame.
- Fazer busca por conteúdos específicos em uma coluna de um DataFrame.

### Aula 05 - Agregações e junções

- Gerar agrupamentos com o método `groupBy`;
- Criar sumarizações com os métodos `agg` e `summary`;
- Utilizar o método `join` para fazer junções entre DataFrame com o uso de chaves de ligação;
- Usar o método `sql` para escrever queries com expressões SQL tradicionais.

### Aula 06 - Formas de armazenamento

- Como criar arquivos CSV com o conteúdo de DataFrames do Spark;
- Sobre o projeto Apache Parquet;
- Como criar arquivos PARQUET com o conteúdo de DataFrames do Spark;
- Como configurar o particionamento de arquivos no Spark.
